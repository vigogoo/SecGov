{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b4bd5f",
   "metadata": {},
   "source": [
    "**All Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eda5a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "# logging\n",
    "import sys\n",
    "import logging\n",
    "import time\n",
    "\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from datetime import date\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "931725a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = Options()\n",
    "opts.use_chromium = True\n",
    "opts.headless = True\n",
    "opts.add_argument(\"disable-gpu\")\n",
    "opts.add_argument(\"--log-level=3\")\n",
    "\n",
    "logging.basicConfig(filename='v.log', filemode='w', level=logging.ERROR, format='%(asctime)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p')\n",
    "\n",
    "try:\n",
    "    driver = Chrome(options=opts, executable_path='./chromedriver.exe') \n",
    "except Exception as e:\n",
    "    logging.error(f'FATAL ERROR! {e}')\n",
    "    sys.exit()\n",
    "\n",
    "# variables\n",
    "BASE_URL = \"https://www.sec.gov/edgar/search/#/\"\n",
    "FILE_BASE_URL = \"https://www.sec.gov/Archives/edgar/data/\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "032917cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_names():\n",
    "    import random\n",
    "    first_names = ['Madelyn','Lamb','Ty','Long','Janiya','Burke','Kameron','Mercer','August','Ibarra','Jabari','Hurley']\n",
    "    last_names = ['Vicente','Stevens','Leonard','Stokes','Judah','Frost','Sophie','Parsons','Sydnee','Ellison','Calvin','Calhoun']\n",
    "    digits = [11,23,45,67,89,30,91,82,73,64,65,54,43,32,21,10]\n",
    "\n",
    "    name = random.choice(first_names) +' '+ random.choice(last_names) \n",
    "     \n",
    "    return name + ' ' + name.replace(' ','')+ str(random.choice(digits))+'@gmail.com'\n",
    "\n",
    "def request_data(url,payload={}):\n",
    "    headers = {\n",
    "        'User-Agent': generate_random_names(),\n",
    "        'Accept-Encoding':'gzip, deflate',\n",
    "        'Host': 'www.sec.gov'\n",
    "        }\n",
    "    r = requests.get(url,headers=headers)\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        # retry 3 times\n",
    "        r = requests.get(url,headers=headers)\n",
    "        if r.status_code != 200:\n",
    "            r = requests.get(url)\n",
    "            if r.status_code != 200:\n",
    "                print(f\"FATAL ERROR: 3 retries failed to retrieve information from url:\\n{url}\")\n",
    "                logging.error(f'FATAL ERROR! 3 retries failed to retrieve information from url:\\n{url}')\n",
    "                return False\n",
    "        #exit() we want the script to continue\n",
    "    return BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "def get_date_string(filing_date_start,filing_date_end=None):\n",
    "#   2017-02-10 --- 2022-02-10\n",
    "#   start_date --- end_date\n",
    "    today = date.today()\n",
    "    five_years_ago = today - datetime.timedelta(days=3*365)\n",
    "    default_start_date = today.strftime(\"%Y-%m-%d\")\n",
    "    default_end_date = five_years_ago.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    if filing_date_start and not filing_date_end:\n",
    "        return  (filing_date_start,filing_date_start)\n",
    "    elif not filing_date_start and  filing_date_end:\n",
    "        return  (filing_date_end,filing_date_end)\n",
    "    elif filing_date_start and filing_date_end:\n",
    "        return  (filing_date_start,filing_date_end)\n",
    "    else:\n",
    "        return (default_end_date,default_start_date)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c914ac49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results are: 18\n",
      "\n",
      "Exhibits Records (exe) Ignored: 1\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_date</th>\n",
       "      <th>filing_no</th>\n",
       "      <th>file_type</th>\n",
       "      <th>file_name</th>\n",
       "      <th>ticker</th>\n",
       "      <th>period_ending</th>\n",
       "      <th>display_names</th>\n",
       "      <th>filing_summa_xml_path</th>\n",
       "      <th>file_path</th>\n",
       "      <th>index_page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022-02-22</td>\n",
       "      <td>000156459022005942</td>\n",
       "      <td>10-K</td>\n",
       "      <td>aple-10k_20211231.htm</td>\n",
       "      <td>0001418121</td>\n",
       "      <td>2021-12-31</td>\n",
       "      <td>Apple Hospitality REIT, Inc.  (APLE)  (CIK 000...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000141...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000141...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000141...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>000156459021054504</td>\n",
       "      <td>10-Q</td>\n",
       "      <td>aple-10q_20210930.htm</td>\n",
       "      <td>0001418121</td>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>Apple Hospitality REIT, Inc.  (APLE)  (CIK 000...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000141...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000141...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000141...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-10-29</td>\n",
       "      <td>000032019321000105</td>\n",
       "      <td>10-K</td>\n",
       "      <td>aapl-20210925.htm</td>\n",
       "      <td>0000320193</td>\n",
       "      <td>2021-09-25</td>\n",
       "      <td>Apple Inc.  (AAPL)  (CIK 0000320193)</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000032...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000032...</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/000032...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     file_date           filing_no file_type              file_name  \\\n",
       "10  2022-02-22  000156459022005942      10-K  aple-10k_20211231.htm   \n",
       "13  2021-11-04  000156459021054504      10-Q  aple-10q_20210930.htm   \n",
       "7   2021-10-29  000032019321000105      10-K      aapl-20210925.htm   \n",
       "\n",
       "        ticker period_ending  \\\n",
       "10  0001418121    2021-12-31   \n",
       "13  0001418121    2021-09-30   \n",
       "7   0000320193    2021-09-25   \n",
       "\n",
       "                                        display_names  \\\n",
       "10  Apple Hospitality REIT, Inc.  (APLE)  (CIK 000...   \n",
       "13  Apple Hospitality REIT, Inc.  (APLE)  (CIK 000...   \n",
       "7                Apple Inc.  (AAPL)  (CIK 0000320193)   \n",
       "\n",
       "                                filing_summa_xml_path  \\\n",
       "10  https://www.sec.gov/Archives/edgar/data/000141...   \n",
       "13  https://www.sec.gov/Archives/edgar/data/000141...   \n",
       "7   https://www.sec.gov/Archives/edgar/data/000032...   \n",
       "\n",
       "                                            file_path  \\\n",
       "10  https://www.sec.gov/Archives/edgar/data/000141...   \n",
       "13  https://www.sec.gov/Archives/edgar/data/000141...   \n",
       "7   https://www.sec.gov/Archives/edgar/data/000032...   \n",
       "\n",
       "                                           index_page  \n",
       "10  https://www.sec.gov/Archives/edgar/data/000141...  \n",
       "13  https://www.sec.gov/Archives/edgar/data/000141...  \n",
       "7   https://www.sec.gov/Archives/edgar/data/000032...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_generic_marketdata(url):\n",
    "    headers = {\n",
    "        'User-Agent': generate_random_names(),\n",
    "        'Accept-Encoding':'gzip, deflate',\n",
    "        'Host': 'www.sec.gov'\n",
    "        }\n",
    "    r = requests.get(url,headers=headers)\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        # retry 3 times\n",
    "        r = requests.get(url,headers=headers)\n",
    "        if r.status_code != 200:\n",
    "            r = requests.get(url)\n",
    "            if r.status_code != 200:\n",
    "                print(f\"FATAL ERROR: 3 retries failed to retrieve information from url:\\n{url}\")\n",
    "                logging.error(f'FATAL ERROR! 3 retries failed to retrieve information from url:\\n{url}')\n",
    "                return False\n",
    "        #exit() we want the script to continue\n",
    "    return BeautifulSoup(r.text, 'lxml') \n",
    "\n",
    "\n",
    "def get_search_results(form_data,max_results_needed=float('inf')):\n",
    "    fd = form_data\n",
    "#     clean date formats first\n",
    "    date_strings = get_date_string( fd.get('filing_date_start'), fd.get('filing_date_end') )\n",
    "#     check if user gave form filings to search by\n",
    "    forms = fd.get('filing_type','') or \"10-K,10-Q\"\n",
    "    url = \"https://efts.sec.gov/LATEST/search-index\"\n",
    "    payload = json.dumps({\n",
    "    \"q\":fd.get('target',''),\n",
    "    \"category\":\"custom\",\n",
    "    \"entityName\":fd.get('ticker',''),\n",
    "    \"forms\":forms.split(','),\n",
    "    \"startdt\":date_strings[0],\n",
    "    \"enddt\":date_strings[1]\n",
    "    })\n",
    "    headers = {\n",
    "      'authority': 'efts.sec.gov',\n",
    "      'accept': 'application/json, text/javascript, */*; q=0.01',\n",
    "      'content-type': 'application/json; charset=UTF-8',\n",
    "      'sec-ch-ua-mobile': '?0',\n",
    "      'user-agent': generate_random_names(),\n",
    "      'origin': 'https://www.sec.gov',\n",
    "      'sec-fetch-site': 'same-site',\n",
    "      'sec-fetch-mode': 'cors',\n",
    "      'sec-fetch-dest': 'empty',\n",
    "      'referer': 'https://www.sec.gov/',\n",
    "    }\n",
    "\n",
    "    r = requests.post(url, headers=headers, data=payload)\n",
    "    if r.status_code != 200:\n",
    "        # retry 3 times\n",
    "        r = requests.post(url, headers=headers, data=payload)\n",
    "        if r.status_code != 200:\n",
    "            r = requests.post(url, headers=headers, data=payload)\n",
    "            if r.status_code != 200:\n",
    "                print(f\"FATAL ERROR: 3 retries failed to retrieve information from url:\\n{url}\")\n",
    "                logging.error(f'FATAL ERROR! 3 retries failed to retrieve information from url:\\n{url}')\n",
    "                return False\n",
    "\n",
    "    response_data = json.loads(r.text)\n",
    "    total_results = response_data.get('hits',{}).get('total',{}).get('value',0)\n",
    "\n",
    "    clean_results = []\n",
    "    print(\"Total results are:\",total_results,end=\"\\n\\n\")\n",
    "    exe = 0\n",
    "    if total_results > 0:\n",
    "\n",
    "    #user passed limits\n",
    "        limit = min(max_results_needed,total_results)\n",
    "    #     add results to total results\n",
    "        results = response_data.get('hits',{}).get('hits',{})\n",
    "        for result in results:\n",
    "            source = result.get('_source',{})\n",
    "\n",
    "    #     clean data avoid exhibit files\n",
    "            if \"ex\" not in source.get('file_type',\"ex\").lower():\n",
    "                filing_no = source.get('adsh').replace(\"-\",\"\")\n",
    "                ticker = source.get('ciks')[0]\n",
    "                index_page = str(FILE_BASE_URL) +  str(ticker) + \"/\" + str(filing_no)\n",
    "                file_name = result.get('_id','').split(\":\")[-1]\n",
    "                data = {\n",
    "                    'file_date' : source.get('file_date'),\n",
    "                    'filing_no' : filing_no,\n",
    "                    'file_type' : source.get('file_type'),\n",
    "                    'file_name' : file_name,\n",
    "                    'ticker' : ticker,\n",
    "                    'period_ending' : source.get('period_ending'),\n",
    "                    'display_names' : \" \".join(source.get('display_names')),\n",
    "                    'filing_summa_xml_path': index_page + \"/\" + 'FilingSummary.xml',\n",
    "                    'file_path': index_page + \"/\" + file_name,\n",
    "                    'index_page': index_page\n",
    "                }\n",
    "                clean_results.append(data)\n",
    "            else:\n",
    "                exe += 1\n",
    "        \n",
    "        print('Exhibits Records (exe) Ignored:',exe,end=\"\\n\\n\")\n",
    "        df = pd.DataFrame.from_dict(clean_results, orient='columns')\n",
    "        df.sort_values(by=['file_date'], inplace=True, ascending=False)\n",
    "        return df[:limit]\n",
    "#     print(\"No Records for this search were found\")\n",
    "    return None\n",
    "    \n",
    "# Test function results\n",
    "get_search_results({'ticker': 'apple',\n",
    " 'filing_type': '',\n",
    " 'search_type': 'T',\n",
    " 'target': 'balance sheet',\n",
    " 'filing_date_start': '2020-01-01',\n",
    " 'filing_date_end': '2022-03-01'},3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68d577",
   "metadata": {},
   "source": [
    "**Form input for Task 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2913cbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_tsk1():\n",
    "    form = {}\n",
    "    form['ticker'] = input('Enter Stock Ticker Symbol>>  ').strip()\n",
    "    form['filing_type'] = input('Enter Filing Type Required (10-K,10-Q,etc)>>  ')\n",
    "#     Is the User search for a financial table or particular Item\n",
    "    while True:\n",
    "        form['search_type'] = input(\"Do you want to search for a Financial Table (T) or Particular Item in Document (I),Please Enter (T) or (I)>>  \").strip()\n",
    "        if form['search_type'].lower() == 't' or form['search_type'].lower() == 'i':\n",
    "            break\n",
    "#     if searching for financial table or searching for particular item\n",
    "    search_type = form['search_type'].lower()\n",
    "    if search_type == 't':\n",
    "        form['target'] = input('Enter Document Required>> ').strip()\n",
    "    else:\n",
    "        while True:\n",
    "            form['item_part'] = input('Do you want to get an item in Part I (1) or Part II (2),Please Enter (1) or (2)>>  ').strip()\n",
    "            if form['item_part'] == '1' or form['item_part'] == '2':\n",
    "                break\n",
    "#       get item number\n",
    "        form['target'] = input('Enter Item Number>> ').strip()\n",
    "    \n",
    "    print('To enter ''Date of Filing'' only enter one date. To enter ''Date period'' enter 2 dates.  ')\n",
    "    form['filing_date_start'] = input('Filed FROM Date: (YYYY-MM-DD)>>  ').strip() or None\n",
    "    form['filing_date_end'] = input('Filed TO Date: (YYYY-MM-DD)>>  ').strip() or None\n",
    "    return form\n",
    "\n",
    "\n",
    "\n",
    "def generate_search_url(data):\n",
    "    for key in data:\n",
    "        if data[key] is None:\n",
    "            data[key] = ''\n",
    "    ''' get search results from sec.gov and save to excel file'''\n",
    "    document = '%2522'+'%2520'.join(data.get('target').split(' '))+'%2522'\n",
    "    date_strings = get_date_string( data.get('filing_date_start'), data.get('filing_date_end') )\n",
    "    forms = data.get('filing_type','') or \"10-K%252C10-Q\"\n",
    "    SEARCH_URL = f\"{BASE_URL}q={document}&category=custom&entityName={data.get('ticker')}&forms={forms}&startdt={date_strings[0]}&enddt={date_strings[1]}\"\n",
    "    print('SEARCH_URL',SEARCH_URL, end=\"\\n\\n\")\n",
    "    return SEARCH_URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd9d870",
   "metadata": {},
   "source": [
    "**Form input for Task 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2942fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inputs_tsk2():\n",
    "    form = {}\n",
    "#   default company names are None\n",
    "    form['ticker'] = None\n",
    "    form['filing_type'] = input('Enter Filing Type Required (10-K,10-Q,etc)>>  ')\n",
    "    while True:\n",
    "        form['item_part'] = input('Do you want to get an item in Part I (1) or Part II (2),Please Enter (1) or (2)>>  ').strip()\n",
    "        if form['item_part'] == '1' or form['item_part'] == '2':\n",
    "            break\n",
    "            \n",
    "#       get item number\n",
    "    form['item_number'] = input('Enter Item Number>> ').strip()\n",
    "    \n",
    "#       keyword or phrase to search with the item number\n",
    "    form['target'] = input('Enter keyword or phrase to search with the item number>> ').strip()\n",
    "    \n",
    "    print('To enter ''Date of Filing'' only enter one date. To enter ''Date period'' enter 2 dates.  ')\n",
    "    form['filing_date_start'] = input('Filed FROM Date: (YYYY-MM-DD)>>  ').strip() or None\n",
    "    form['filing_date_end'] = input('Filed TO Date: (YYYY-MM-DD)>>  ').strip() or None\n",
    "    return form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b6e10",
   "metadata": {},
   "source": [
    "**Extractor function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "721533b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy test content for the extractor\n",
    "\n",
    "contents = \"\"\"\n",
    "(1) Index to Consolidated Financial Statements:\n",
    "Report of Ernst & Young LLP, Independent Registered Public Accounting Firm\n",
    "Consolidated Statements of Cash Flows for each of the three years ended December 31, 2021\n",
    "Consolidated Statements of Operations for each of the three years ended December 31, 2021\n",
    "Consolidated Statements of Comprehensive Income for each of the three years ended December 31, 2021\n",
    "Consolidated Balance Sheets as of December 31, 2020 and 2021\n",
    "Consolidated Statements of Stockholders’ Equity for each of the three years ended December 31, 2021\n",
    "Notes to Consolidated Financial Statements\n",
    "Report of Ernst & Young LLP, Independent Registered Public Accounting Firm\n",
    "(2 ) Indexiasz ad to Financial Statement Schedules\n",
    "All schedules have been omitted because the required information is included in the consolidated financial statements or the notes thereto, or because it is not required.\n",
    "(3) Index to Exhibits Kenya\n",
    "See exhibits listed under Part (b) below.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "563f4066",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def content_extractor(content,start_pt,start_pattern,end_pt,end_pattern,size=10):\n",
    "    start_candidates = []\n",
    "    end_candidates = []\n",
    "    \n",
    "#     get possible starting points in content\n",
    "    possible_starts = [match for match in re.finditer(start_pt, content, flags=re.IGNORECASE)]\n",
    "    \n",
    "#     no starting point found\n",
    "    if not possible_starts:\n",
    "        return False\n",
    "    \n",
    "    \n",
    "#  get start candidates\n",
    "    for candidate in possible_starts:\n",
    "        start = candidate.start()\n",
    "        back_step = max(0,start-size)\n",
    "        if (end := re.compile(start_pattern,flags=re.IGNORECASE).search(content,back_step,start)):\n",
    "            start_candidates.append(end.start())\n",
    "\n",
    "# no starting candidates found after cleaning  \n",
    "    if not start_candidates:\n",
    "        return False\n",
    "    \n",
    "\n",
    "#     if stopping point was passed\n",
    "    if end_pt:\n",
    "    #  get possible stopping point in content else ending point is end of content\n",
    "        possible_endings = [match for match in re.finditer(end_pt, content, flags=re.IGNORECASE)]\n",
    "        \n",
    "        \n",
    "    # get ending candidates if no ending candidates found get upto end of string\n",
    "        for candidate in possible_endings:\n",
    "            start = candidate.start()\n",
    "            back_step = max(0,start-size)\n",
    "            if (end := re.compile(end_pattern,flags=re.IGNORECASE).search(content,back_step,start)):\n",
    "                end_candidates.append(end.start())\n",
    "\n",
    "# There is a start but no end\n",
    "    if not end_candidates:\n",
    "        return content[start_candidates[0] - 1:]\n",
    "    \n",
    "    results = \"\\n\\n\"\n",
    "#   catch if any case ending candidates are less than starting candidate\n",
    "    try:\n",
    "        for i,j in enumerate(start_candidates):\n",
    "            results += content[j - 1:end_candidates[i] - 1] + \"\\n\\n\\n\\n\\n\"\n",
    "    except IndexError:\n",
    "        index_breaked = len(end_candidates)\n",
    "        results += content[start_candidates[index_breaked]:] + \"\\n\\n\\n\\n\\n\"\n",
    "        \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c531ca90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "(1) Index to Consolidated Financial Statements:\n",
      "Report of Ernst & Young LLP, Independent Registered Public Accounting Firm\n",
      "Consolidated Statements of Cash Flows for each of the three years ended December 31, 2021\n",
      "Consolidated Statements of Operations for each of the three years ended December 31, 2021\n",
      "Consolidated Statements of Comprehensive Income for each of the three years ended December 31, 2021\n",
      "Consolidated Balance Sheets as of December 31, 2020 and 2021\n",
      "Consolidated Statements of Stockholders’ Equity for each of the three years ended December 31, 2021\n",
      "Notes to Consolidated Financial Statements\n",
      "Report of Ernst & Young LLP, Independent Registered Public Accounting Firm\n",
      "(2 ) Indexiasz ad to Financial Statement Schedules\n",
      "All schedules have been omitted because the required information is included in the consolidated financial statements or the notes thereto, or because it is not required.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test constructor by calls\n",
    "print(content_extractor(\n",
    "    contents,\n",
    "    'Index to Consolidated Financial Statements',\n",
    "    '\\(1\\)|\\( 1\\)|\\(1 \\)|\\(1.\\)',\n",
    "    'Index to Exhibits Kenya|Index to Exhibits Uganda',\n",
    "    '\\(3\\)|\\( 3\\)|\\(3 \\)|\\(3.\\)',\n",
    "    size=10\n",
    "))\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28b40fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc3ded521ee48927cd256be851c757c3495791bf0a02a2a9e3c6b3044ceb0e23"
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
